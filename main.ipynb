{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import string\n",
    "from spacy.lang.en import English\n",
    "\n",
    "from preprocessing import *\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "#from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing\n",
      "TO_LOWER\n",
      "REMOVE_EMOJI\n",
      "REMOVE_EMOTICONS\n",
      "CHAT_WORDS_CONVERSION\n",
      "SPELL_CORRECT\n",
      "ADD_SPACE\n",
      "REMOVE_STOPWORDS\n",
      "REMOVE_URL\n",
      "preparing\n",
      "TO_LOWER\n",
      "REMOVE_EMOJI\n",
      "REMOVE_EMOTICONS\n",
      "CHAT_WORDS_CONVERSION\n",
      "SPELL_CORRECT\n",
      "ADD_SPACE\n",
      "REMOVE_STOPWORDS\n",
      "REMOVE_URL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>trump supporters needed 4 democrats socialist ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>send back!!why hell im sick hearing ifwe great...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>yeah... im wondering send works wife camp 3 kn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>know realize cant pretend didnt know obama beg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>donny owe people apology applauding horrible c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>1496</td>\n",
       "      <td>white person migrated obviously hated america ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>1497</td>\n",
       "      <td>talk 1 hes dumbass texts 2 love mean 3 dick du...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>1498</td>\n",
       "      <td>send love leave different things</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1499</td>\n",
       "      <td>trump wants end racist chants needs repeat sen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>1500</td>\n",
       "      <td>maybe meant send home state... washington</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               Text  Class\n",
       "0        1  trump supporters needed 4 democrats socialist ...      0\n",
       "1        2  send back!!why hell im sick hearing ifwe great...      1\n",
       "2        3  yeah... im wondering send works wife camp 3 kn...      1\n",
       "3        4  know realize cant pretend didnt know obama beg...      1\n",
       "4        5  donny owe people apology applauding horrible c...      0\n",
       "...    ...                                                ...    ...\n",
       "1495  1496  white person migrated obviously hated america ...      1\n",
       "1496  1497  talk 1 hes dumbass texts 2 love mean 3 dick du...      0\n",
       "1497  1498                   send love leave different things      1\n",
       "1498  1499  trump wants end racist chants needs repeat sen...      0\n",
       "1499  1500          maybe meant send home state... washington      1\n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TrainingDS.csv')\n",
    "prep_train = PrepareText(df, spell_correct=True, remove_punct=False)\n",
    "prep_train.prepare()\n",
    "prep_train.save_file('prep_train.csv')\n",
    "df = prep_train.df\n",
    "\n",
    "df_sample = pd.read_csv('Sample Submission.csv')\n",
    "df_test = pd.read_csv('TestingDS.csv')\n",
    "prep_test = PrepareText(df_test, spell_correct=True, remove_punct=False)\n",
    "prep_test.prepare()\n",
    "prep_test.save_file('prep_test.csv')\n",
    "df_test = prep_test.df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      1500 non-null   int64 \n",
      " 1   Text    1500 non-null   object\n",
      " 2   Class   1500 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 35.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>750.500000</td>\n",
       "      <td>0.386667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>433.157015</td>\n",
       "      <td>0.487149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>375.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>750.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1125.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID        Class\n",
       "count  1500.000000  1500.000000\n",
       "mean    750.500000     0.386667\n",
       "std     433.157015     0.487149\n",
       "min       1.000000     0.000000\n",
       "25%     375.750000     0.000000\n",
       "50%     750.500000     0.000000\n",
       "75%    1125.250000     1.000000\n",
       "max    1500.000000     1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    920\n",
       "1    580\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = df['Class'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with nlp.disable_pipes():\n",
    "    doc_vectors = np.array([nlp(text).vector for text in df['Text']])\n",
    "    \n",
    "doc_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(doc_vectors, df['Class'],\n",
    "                                                    test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.333%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(random_state=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(random_state=1)\n",
    "svc.fit(X_train, y_train)\n",
    "print(f\"Accuracy: {svc.score(X_test, y_test) * 100:.3f}%\", )\n",
    "svc.fit(doc_vectors, df['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Class\n",
       "0   1      1\n",
       "1   2      0\n",
       "2   3      0\n",
       "3   4      0\n",
       "4   5      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ye bhi illegal immigrant lag rah hai arc regis...</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>yeah asked skirt today said ass like don't tim...</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>need clean selective hearing cobwebs ears tell...</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>easy complain criticize offering solution clos...</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>guess send-them-back policy friend hit little ...</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Text Class\n",
       "0   1  ye bhi illegal immigrant lag rah hai arc regis...     ?\n",
       "1   2  yeah asked skirt today said ass like don't tim...     ?\n",
       "2   3  need clean selective hearing cobwebs ears tell...     ?\n",
       "3   4  easy complain criticize offering solution clos...     ?\n",
       "4   5  guess send-them-back policy friend hit little ...     ?"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with nlp.disable_pipes():\n",
    "    doc_vectors_test = np.array([nlp(text).vector for text in df_test.Text])\n",
    "doc_vectors_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = svc.predict(doc_vectors_test)\n",
    "predict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ye bhi illegal immigrant lag rah hai arc regis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>yeah asked skirt today said ass like don't tim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>need clean selective hearing cobwebs ears tell...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>easy complain criticize offering solution clos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>guess send-them-back policy friend hit little ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Text  Class\n",
       "0   1  ye bhi illegal immigrant lag rah hai arc regis...      1\n",
       "1   2  yeah asked skirt today said ass like don't tim...      1\n",
       "2   3  need clean selective hearing cobwebs ears tell...      0\n",
       "3   4  easy complain criticize offering solution clos...      1\n",
       "4   5  guess send-them-back policy friend hit little ...      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Class'] = predict\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop('Text', axis=1).to_csv('test_predict.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle score: 0.76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump supporters needed 4 democrats socialist squad racist trump america supporters america freedom speech trump hyper rally socialist democratic squad rally rally said send migrants socialist democratic\n"
     ]
    }
   ],
   "source": [
    "test_text = df.iloc[0]['Text']\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomOverSampler - for imbalanced target "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Removing spaces and converting text into lowercase\n",
    "    return text.strip().lower()\n",
    "\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        # Cleaning Text\n",
    "        return [clean_text(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF and Bag of Words transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,2))\n",
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer, min_df=3, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Text'], \n",
    "    df['Class'], \n",
    "    test_size=0.2, \n",
    "    stratify=df['Class'], \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTest(pipe, df_test, name_file):\n",
    "    pipe.fit(df['Text'], df['Class'])\n",
    "    predict = pipe.predict(df_test['Text'])\n",
    "    df_test['Class'] = predict\n",
    "    df_test.drop('Text', axis=1).to_csv(name_file+'.csv', index=False, sep=',')\n",
    "    print('Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Creating a Pipeline and Generating the Model</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Accuracy: \t 0.86\n",
      "TF-IDF Precision: \t 0.8032786885245902\n",
      "TF-IDF Recall: \t\t 0.8448275862068966\n",
      "TF-IDF f1: \t\t 0.823529411764706\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(random_state=42, n_estimators=100, min_samples_split=5)\n",
    "classifier = LogisticRegression(\n",
    "    random_state=42, \n",
    "    penalty='elasticnet', \n",
    "    solver='saga', \n",
    "    l1_ratio=.05,\n",
    "    max_iter=200\n",
    ") # kaggle 0.81 0.84\n",
    "\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', tfidf_vector),\n",
    "                 ('RUS', RandomOverSampler()),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"TF-IDF Accuracy: \\t\", sklearn.metrics.accuracy_score(y_test, predicted))\n",
    "print(\"TF-IDF Precision: \\t\", sklearn.metrics.precision_score(y_test, predicted))\n",
    "print(\"TF-IDF Recall: \\t\\t\", sklearn.metrics.recall_score(y_test, predicted))\n",
    "print(\"TF-IDF f1: \\t\\t\", sklearn.metrics.f1_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "saveTest(pipe, df_test, 'test_predict2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Accuracy: \t 0.86\n",
      "Bag of Words Precision:  0.8032786885245902\n",
      "Bag of Words Recall: \t 0.8448275862068966\n",
      "Bag of Words f1: \t 0.823529411764706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ирик\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "pipe2 = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('RUS', RandomOverSampler()),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe2.fit(X_train,y_train)\n",
    "predicted = pipe2.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Bag of Words Accuracy: \\t\", sklearn.metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Bag of Words Precision: \", sklearn.metrics.precision_score(y_test, predicted))\n",
    "print(\"Bag of Words Recall: \\t\", sklearn.metrics.recall_score(y_test, predicted))\n",
    "print(\"Bag of Words f1: \\t\", sklearn.metrics.f1_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "saveTest(pipe, df_test, 'test_predict3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- logreg TF-IDF = 0.82666\n",
    "- logreg Bog = 0.83500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
