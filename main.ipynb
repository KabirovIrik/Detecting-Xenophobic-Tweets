{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import string\n",
    "from spacy.lang.en import English\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "#from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Trump supporters needed to say the 4 Democrats...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Send them back!!Why the hell are they even her...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Yeah...Im wondering if send them back works fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I know you realize you cant pretend that you d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Donny, you owe all people an apology for appla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>1496</td>\n",
       "      <td>If a white person Migrated here and obvisouly ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>1497</td>\n",
       "      <td>Talk about 1 Hes a dumbass who never texts bac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>1498</td>\n",
       "      <td>Send them Back and Love it or leave it are two...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1499</td>\n",
       "      <td>If Trump wants to end racist chants all he nee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>1500</td>\n",
       "      <td>maybe they meant send her back to her home sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               Text  Class\n",
       "0        1  Trump supporters needed to say the 4 Democrats...      0\n",
       "1        2  Send them back!!Why the hell are they even her...      1\n",
       "2        3  Yeah...Im wondering if send them back works fo...      1\n",
       "3        4  I know you realize you cant pretend that you d...      1\n",
       "4        5  Donny, you owe all people an apology for appla...      0\n",
       "...    ...                                                ...    ...\n",
       "1495  1496  If a white person Migrated here and obvisouly ...      1\n",
       "1496  1497  Talk about 1 Hes a dumbass who never texts bac...      0\n",
       "1497  1498  Send them Back and Love it or leave it are two...      1\n",
       "1498  1499  If Trump wants to end racist chants all he nee...      0\n",
       "1499  1500  maybe they meant send her back to her home sta...      1\n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TrainingDS.csv')\n",
    "df_sample = pd.read_csv('Sample Submission.csv')\n",
    "df_test = pd.read_csv('TestingDS.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      1500 non-null   int64 \n",
      " 1   Text    1500 non-null   object\n",
      " 2   Class   1500 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 35.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>750.500000</td>\n",
       "      <td>0.386667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>433.157015</td>\n",
       "      <td>0.487149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>375.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>750.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1125.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID        Class\n",
       "count  1500.000000  1500.000000\n",
       "mean    750.500000     0.386667\n",
       "std     433.157015     0.487149\n",
       "min       1.000000     0.000000\n",
       "25%     375.750000     0.000000\n",
       "50%     750.500000     0.000000\n",
       "75%    1125.250000     1.000000\n",
       "max    1500.000000     1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    920\n",
       "1    580\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = df['Class'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with nlp.disable_pipes():\n",
    "    doc_vectors = np.array([nlp(text).vector for text in df['Text']])\n",
    "    \n",
    "doc_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(doc_vectors, df['Class'],\n",
    "                                                    test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.333%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(random_state=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(random_state=1)\n",
    "svc.fit(X_train, y_train)\n",
    "print(f\"Accuracy: {svc.score(X_test, y_test) * 100:.3f}%\", )\n",
    "svc.fit(doc_vectors, df['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Class\n",
       "0   1      1\n",
       "1   2      0\n",
       "2   3      0\n",
       "3   4      0\n",
       "4   5      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ye bhi illegal immigrant lag rahi hai -- NRC r...</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Yeah I asked someone about her skirt today and...</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>You need to clean your SELECTIVE HEARING COBWE...</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>It easy to complain and criticize with no offe...</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Guess the send-them-back policy of your friend...</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Text Class\n",
       "0   1  Ye bhi illegal immigrant lag rahi hai -- NRC r...     ?\n",
       "1   2  Yeah I asked someone about her skirt today and...     ?\n",
       "2   3  You need to clean your SELECTIVE HEARING COBWE...     ?\n",
       "3   4  It easy to complain and criticize with no offe...     ?\n",
       "4   5  Guess the send-them-back policy of your friend...     ?"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with nlp.disable_pipes():\n",
    "    doc_vectors_test = np.array([nlp(text).vector for text in df_test.Text])\n",
    "doc_vectors_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = svc.predict(doc_vectors_test)\n",
    "predict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ye bhi illegal immigrant lag rahi hai -- NRC r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Yeah I asked someone about her skirt today and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>You need to clean your SELECTIVE HEARING COBWE...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>It easy to complain and criticize with no offe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Guess the send-them-back policy of your friend...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Text  Class\n",
       "0   1  Ye bhi illegal immigrant lag rahi hai -- NRC r...      1\n",
       "1   2  Yeah I asked someone about her skirt today and...      1\n",
       "2   3  You need to clean your SELECTIVE HEARING COBWE...      0\n",
       "3   4  It easy to complain and criticize with no offe...      1\n",
       "4   5  Guess the send-them-back policy of your friend...      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Class'] = predict\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop('Text', axis=1).to_csv('test_predict.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle score: 0.78333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump supporters needed to say the 4 Democrats socialist Squad are racist towards Trump America supporter. America has freedom of speech and it was a Trump hyper rally not a Socialist Democratic squad rally. The rally said send her back the one not migrants Socialist Democratic\n"
     ]
    }
   ],
   "source": [
    "test_text = df.iloc[0]['Text']\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomOverSampler - for imbalanced target "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Removing spaces and converting text into lowercase\n",
    "    return text.strip().lower()\n",
    "\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        # Cleaning Text\n",
    "        return [clean_text(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF and Bag of Words transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,2))\n",
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer, min_df=3, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Text'], \n",
    "    df['Class'], \n",
    "    test_size=0.2, \n",
    "    stratify=df['Class'], \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTest(pipe, df_test, name_file):\n",
    "    pipe.fit(df['Text'], df['Class'])\n",
    "    predict = pipe.predict(df_test['Text'])\n",
    "    df_test['Class'] = predict\n",
    "    df_test.drop('Text', axis=1).to_csv(name_file+'.csv', index=False, sep=',')\n",
    "    print('Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Creating a Pipeline and Generating the Model</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Accuracy: \t 0.8566666666666667\n",
      "TF-IDF Precision: \t 0.8016528925619835\n",
      "TF-IDF Recall: \t\t 0.8362068965517241\n",
      "TF-IDF f1: \t\t 0.8185654008438819\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(random_state=42, n_estimators=100, min_samples_split=5)\n",
    "classifier = LogisticRegression(\n",
    "    random_state=42, \n",
    "    penalty='elasticnet', \n",
    "    solver='saga', \n",
    "    l1_ratio=.05,\n",
    "    max_iter=200\n",
    ") # kaggle 0.81 0.84\n",
    "\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', tfidf_vector),\n",
    "                 ('RUS', RandomOverSampler()),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"TF-IDF Accuracy: \\t\", sklearn.metrics.accuracy_score(y_test, predicted))\n",
    "print(\"TF-IDF Precision: \\t\", sklearn.metrics.precision_score(y_test, predicted))\n",
    "print(\"TF-IDF Recall: \\t\\t\", sklearn.metrics.recall_score(y_test, predicted))\n",
    "print(\"TF-IDF f1: \\t\\t\", sklearn.metrics.f1_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "saveTest(pipe, df_test, 'test_predict2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Accuracy: \t 0.86\n",
      "Bag of Words Precision:  0.8303571428571429\n",
      "Bag of Words Recall: \t 0.8017241379310345\n",
      "Bag of Words f1: \t 0.8157894736842104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ирик\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "pipe2 = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('RUS', RandomOverSampler()),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe2.fit(X_train,y_train)\n",
    "predicted = pipe2.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Bag of Words Accuracy: \\t\", sklearn.metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Bag of Words Precision: \", sklearn.metrics.precision_score(y_test, predicted))\n",
    "print(\"Bag of Words Recall: \\t\", sklearn.metrics.recall_score(y_test, predicted))\n",
    "print(\"Bag of Words f1: \\t\", sklearn.metrics.f1_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "saveTest(pipe, df_test, 'test_predict3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- logreg TF-IDF = 0.84416\n",
    "- logreg Bog = 0.846"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
